# -*- coding: utf-8 -*-
"""train_cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sIbwi_D3NI_kILxw6Mx8H-2DXW-9Mxd4
"""

from google.colab import drive
drive.mount('/content/gdrive')

# %tensorflow_version 1.x

import tensorflow
print(tensorflow.__version__)

from keras.models import Sequential
#Import from keras_preprocessing not from keras.preprocessing
from keras_preprocessing.image import ImageDataGenerator
from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization
from keras.layers import Conv2D, MaxPooling2D
from keras import regularizers, optimizers
import pandas as pd
import numpy as np

traindf=pd.read_csv('/content/gdrive/My Drive/Dane_form_detection/Prepared_data/train.csv',dtype=str)
testdf=pd.read_csv('/content/gdrive/My Drive/Dane_form_detection/Prepared_data/test.csv',dtype=str)

print(traindf)

datagen=ImageDataGenerator(rescale=1./255.,
                           validation_split=0.2)
train_generator=datagen.flow_from_dataframe(dataframe=traindf,
                                            directory='/content/gdrive/My Drive/Dane_form_detection/Prepared_data/train',
                                            x_col="Image",
                                            y_col="target",
                                            subset="training",
                                            batch_size=32,
                                            seed=42,
                                            shuffle=True,
                                            drop_duplicates = False,
                                            class_mode="categorical",
                                            target_size=(224,224))
valid_generator=datagen.flow_from_dataframe(dataframe=traindf,
                                            directory='/content/gdrive/My Drive/Dane_form_detection/Prepared_data/train',
                                            x_col="Image",
                                            y_col="target",
                                            subset="validation",
                                            batch_size=32,
                                            seed=42,
                                            shuffle=True,
                                            drop_duplicates = False,
                                            class_mode="categorical",
                                            target_size=(224,224))
test_datagen=ImageDataGenerator(rescale=1./255.)
test_generator=test_datagen.flow_from_dataframe(dataframe=testdf,
                                                directory= '/content/gdrive/My Drive/Dane_form_detection/Prepared_data/test',
                                                x_col="Image",
                                                y_col=None,
                                                batch_size=1,
                                                seed=42,
                                                drop_duplicates =False,
                                                shuffle=False,
                                                class_mode=None,
                                                target_size=(224,224))

model = Sequential()
model.add(Conv2D(32, (3, 3), padding='same',
                 input_shape=(224,224,3)))
model.add(Activation('relu'))
model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Conv2D(64, (3, 3), padding='same'))
model.add(Activation('relu'))
model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(8, activation='softmax'))
# lr_schedule = optimizers.schedules.ExponentialDecay(
#     initial_learning_rate=1e-2,
#     decay_steps=10000,
#     decay_rate=0.9)
# optimizer = optimizers.SGD(learning_rate=0.01)
optimizer = optimizers.Adam(lr=0.0001, decay=1e-6)
model.compile(optimizer,loss="categorical_crossentropy",metrics=["accuracy"])

model.summary()

STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size
STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size
STEP_SIZE_TEST=test_generator.n//test_generator.batch_size

history  = model.fit_generator(generator=train_generator,
                    steps_per_epoch=STEP_SIZE_TRAIN,
                    validation_data=valid_generator,
                    validation_steps=STEP_SIZE_VALID,
                    epochs=100)

model.save_weights("dance_form_model.h5")

(eval_loss, eval_accuracy) = model.evaluate_generator(generator=valid_generator,
steps=STEP_SIZE_VALID)

print("[INFO] accuracy: {:.2f}%".format(eval_accuracy * 100)) 
print("[INFO] Loss: {}".format(eval_loss))

#Graphing our training and validation
import matplotlib.pyplot as plt
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(acc))
plt.plot(epochs, acc, 'r', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.ylabel('accuracy') 
plt.xlabel('epoch')
plt.legend()
plt.figure()
plt.plot(epochs, loss, 'r', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.ylabel('loss') 
plt.xlabel('epoch')
plt.legend()
plt.show()

test_generator.reset()
pred=model.predict_generator(test_generator,
steps=STEP_SIZE_TEST,
verbose=1)
print(pred)

predicted_class_indices=np.argmax(pred,axis=1)
print(predicted_class_indices)
len(predicted_class_indices)

labels = (train_generator.class_indices)
labels = dict((v,k) for k,v in labels.items())
predictions = [labels[k] for k in predicted_class_indices]
print(predictions)
len(predictions)

# from sklearn import metrics
# from sklearn.metrics import confusion_matrix
# dances = ['manipuri','bharatanatyam','odissi','kathakali','kathak','sattriya','kuchipudi','mohiniyattam']
# classification_metrics = metrics.classification_report(labels,pred,target_names = dances)

filenames=test_generator.filenames
print(len(filenames))
print(filenames)
results=pd.DataFrame({"Image":filenames,
                      "target":predictions})
print(results)
results.to_csv("results.csv",index=False)

